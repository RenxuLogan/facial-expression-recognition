{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5381f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入必要依赖库\n",
    "import torch.optim\n",
    "import  torchvision\n",
    "from torch.nn import Linear, Flatten, MaxPool2d, Conv2d\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import  nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn.init as init\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3e1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=7):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        #self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "593f1f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文件夹准备\n",
    "# 拼接模型保存路径\n",
    "folder_path = \"../models/res_parm\"\n",
    "\n",
    "Train_data_path = '../RAF/images/train'\n",
    "test_data_path = \"../RAF/images/test\"\n",
    "\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12030c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###准备数据集和测试集\n",
    "###Tensor 形状： torch.Size([3, 100, 100]) 图像模式： RGB\n",
    "transform = torchvision.transforms.Compose([\n",
    "     torchvision.transforms.Resize((48,48)),          #统一尺寸\n",
    "    torchvision.transforms.ToTensor(),                   # 转换为 [C, H, W] 的张量，范围 [0, 1]\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                      std=[0.229, 0.224, 0.225])  \n",
    "])\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((48, 48)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),       # 水平翻转\n",
    "    torchvision.transforms.RandomRotation(10),                # 旋转 ±10°\n",
    "    torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1),  # 颜色抖动\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "added13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "loss_function=loss_function.cuda()\n",
    "\n",
    "torch.cuda.empty_cache()## 训练之前清理显存避免显存爆炸\n",
    "\n",
    "lr_values = [1e-3, 1e-4, 1e-5]\n",
    "batch_size_values = [32,64, 128, 256]\n",
    "epochs_values = [15, 25, 30]\n",
    "weight_decay_values= [ 1e-4, 1e-5,1e-6]\n",
    "best_acc_values_in_each=[]\n",
    "Res_values = [ [2, 2, 2, 2], [3,4,5,3] , [3, 4, 6, 3]]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9b0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练：lr=0.001, res=[2, 2, 2, 2],weight_decay=0.0001,batch_size=32, epochs=15\n",
      "---------第1轮训练开始---------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-585f9d79d4f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                             \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                             \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "for res_values in Res_values:\n",
    "    for lr in lr_values:\n",
    "        for weight_decay in weight_decay_values:\n",
    "            for batch_size in batch_size_values:\n",
    "                for epochs in epochs_values:\n",
    "\n",
    "                    total_train_step = 0\n",
    "                    \n",
    "                    model = ResNet(BasicBlock, res_values, num_classes=7)  \n",
    "                    model.cuda()\n",
    "                    best_acc = 0\n",
    "\n",
    "                    accuracies=[]\n",
    "                    losses = []\n",
    "\n",
    "                    train_data = torchvision.datasets.ImageFolder(root=Train_data_path, transform=train_transform)\n",
    "                    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "\n",
    "                    test_data = torchvision.datasets.ImageFolder(root=test_data_path, transform=transform)\n",
    "                    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False,drop_last=True)\n",
    "\n",
    "                    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "                    train_data_len = len(train_data)\n",
    "                    test_data_len = len(test_data)\n",
    "\n",
    "                    print(f\"开始训练：lr={lr}, res={res_values},weight_decay={weight_decay},batch_size={batch_size}, epochs={epochs}\")\n",
    "\n",
    "                    for i in range(epochs):\n",
    "                        print(\"---------第{}轮训练开始---------\".format(i+1))\n",
    "                        model.train()\n",
    "                        for data in train_loader:\n",
    "                            img,target = data\n",
    "                            img= img.cuda()\n",
    "                            target = target.cuda()\n",
    "                            output = model(img)\n",
    "\n",
    "                            loss=loss_function(output,target)\n",
    "                            optimizer.zero_grad()\n",
    "\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            \n",
    "                            total_train_step+=1\n",
    "\n",
    "                            if total_train_step % 100==0:\n",
    "                                print(\"训练次数{}，Loss：{}\".format(total_train_step,loss.item()))\n",
    "                        #测试步骤\n",
    "                        total_test_loss = 0\n",
    "                        total_accuracy = 0\n",
    "                        with torch.no_grad():\n",
    "                            model.eval()\n",
    "                            for data in test_loader :\n",
    "                                img,target = data\n",
    "                                img = img.cuda()\n",
    "                                target = target.cuda()\n",
    "                                output= model(img)\n",
    "                                loss = loss_function(output,target)\n",
    "                                total_test_loss+=loss.item()\n",
    "                                accuracy = (output.argmax(1) == target ).sum().item()\n",
    "                                total_accuracy += accuracy\n",
    "                        if(total_accuracy/test_data_len>best_acc):\n",
    "                            best_acc = total_accuracy/test_data_len\n",
    "                        print(\"正确率{}\".format(total_accuracy/test_data_len))\n",
    "                        accuracies.append(total_accuracy/test_data_len)\n",
    "                        print(\"整体测试集上的Loss{}\".format(total_test_loss))\n",
    "                        losses.append(total_test_loss)\n",
    "                    \n",
    "                    best_acc_values_in_each.append(best_acc)\n",
    "                    results.append({\n",
    "                        \"Block_value\":res_values,\n",
    "                        'Learning Rate': lr,\n",
    "                        'Weight Decay': weight_decay,\n",
    "                        'Batch Size': batch_size,\n",
    "                        'Epochs': epochs,\n",
    "                        'Best Accuracy': best_acc\n",
    "                    })\n",
    "\n",
    "                    #画图并保存\n",
    "                    epochs = list(range(1, len(accuracies)+1))\n",
    "\n",
    "                    plt.figure(figsize=(10, 4))\n",
    "\n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    plt.plot(epochs, accuracies, label='Accuracy', marker='o')\n",
    "                    plt.xlabel(\"Epoch\")\n",
    "                    plt.ylabel(\"Accuracy\")\n",
    "                    plt.title(\"Validation Accuracy\")\n",
    "                    plt.grid(True)\n",
    "\n",
    "                    plt.subplot(1, 2, 2)\n",
    "                    plt.plot(epochs, losses, label='Test Loss', color='orange', marker='o')\n",
    "                    plt.xlabel(\"Epoch\")\n",
    "                    plt.ylabel(\"Loss\")\n",
    "                    plt.title(\"Validation Loss\")\n",
    "                    plt.grid(True)\n",
    "\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    save_path = os.path.join(folder_path, \n",
    "                                            f\"accuracy_and_loss_Block_{res_values}_lr_{lr}_wd_{weight_decay}_bs_{batch_size}_epochs_{epochs}.png\")\n",
    "                    plt.savefig(save_path)\n",
    "                                    \n",
    "                    print(f\"图像已保存到: {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d49eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# 保存路径\n",
    "file_path = \"../hyperparameter_results_res.xlsx\"\n",
    "df.to_excel(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
